# ğŸ”§ ä¿®æ­£ç‰ˆé…ç½®æ–‡ä»¶ - è§£å†³ç»´åº¦ä¸åŒ¹é…é—®é¢˜

flux_path: "/root/autodl-tmp/qyt/hfd_model"
dtype: "bfloat16"

model:
  union_cond_attn: true
  add_cond_attn: false
  latent_lora: false
  use_sep: false

  # ========================================
  # ğŸ”§ ä¿®æ­£åçš„è¯­ä¹‰æ¡ä»¶é…ç½®
  # ========================================
  use_semantic_conditioning: true

  # ğŸ”§ é‡è¦: fusionæ–¹æ³•åªèƒ½ä½¿ç”¨ä»¥ä¸‹ä¸‰ç§ (concatå·²åºŸå¼ƒ)
  # - weighted: å›ºå®šæƒé‡çš„ç‰¹å¾èåˆ (æœ€ç®€å•,æ¨èæ–°æ‰‹)
  # - learnable_weighted: å¯å­¦ä¹ æƒé‡èåˆ (æ¨è,æ•ˆæœæœ€å¥½)
  # - pixel_fusion: åƒç´ çº§èåˆåå†ç¼–ç  (å¤‡é€‰)
  semantic_fusion_method: "learnable_weighted"  # ğŸ”§ æ¨èä½¿ç”¨æ­¤æ¨¡å¼

  # æƒé‡å‚æ•° (ä»…weightedå’Œpixel_fusionæ¨¡å¼éœ€è¦)
  semantic_weight: 0.5  # èŒƒå›´ [0, 1], 0=åªç”¨å¯è§å…‰, 1=åªç”¨è¯­ä¹‰

  # ğŸ”§ æ–°å¢: æ®‹å·®èåˆé€‰é¡¹ (ä»…weightedæ¨¡å¼)
  use_residual_fusion: true  # ä¿ç•™æ›´å¤šå¯è§å…‰ä¿¡æ¯,å‡å°‘ä¿¡æ¯æŸå¤±

train:
  batch_size: 4
  accumulate_grad_batches: 1
  dataloader_workers: 4
  save_interval: 1000
  sample_interval: 1000
  max_steps: -1
  gradient_checkpointing: true
  save_path: "runs"

  condition_type: "vis2ir_semantic"
  dataset:
    type: "vis2ir_semantic"
    path: "/root/autodl-tmp/qyt_1/dataset/pid_llvip_dataset.parquet"
    condition_size: 512
    target_size: 512
    image_size: 512
    padding: 8
    drop_text_prob: 0.1
    drop_image_prob: 0.0
    include_semantic: true
    semantic_column: panoptic_img

  wandb:
    project: "Vis2IR-Semantic-Corrected"

  lora_config:
    r: 32
    lora_alpha: 32
    init_lora_weights: "gaussian"
    target_modules: "(.*x_embedder|.*(?<!single_)transformer_blocks\\.[0-9]+\\.norm1\\.linear|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_k|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_q|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_v|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_out\\.0|.*(?<!single_)transformer_blocks\\.[0-9]+\\.ff\\.net\\.2|.*single_transformer_blocks\\.[0-9]+\\.norm\\.linear|.*single_transformer_blocks\\.[0-9]+\\.proj_mlp|.*single_transformer_blocks\\.[0-9]+\\.proj_out|.*single_transformer_blocks\\.[0-9]+\\.attn.to_k|.*single_transformer_blocks\\.[0-9]+\\.attn.to_q|.*single_transformer_blocks\\.[0-9]+\\.attn.to_v|.*single_transformer_blocks\\.[0-9]+\\.attn.to_out)"

  optimizer:
    type: "Prodigy"
    params:
      lr: 1
      use_bias_correction: true
      safeguard_warmup: true
      weight_decay: 0.01


# ========================================
# ğŸ”§ é…ç½®è¯´æ˜
# ========================================
#
# 1. semantic_fusion_method å¯¹æ¯”:
#
#    weighted (å›ºå®šæƒé‡):
#      - æœ€ç®€å•,æ— é¢å¤–å‚æ•°
#      - éœ€è¦æ‰‹åŠ¨è°ƒsemantic_weight
#      - æ¨èèŒƒå›´: 0.3-0.7
#
#    learnable_weighted (å¯å­¦ä¹ æƒé‡):  â­ æ¨è
#      - è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜èåˆæ¯”ä¾‹
#      - æ— éœ€æ‰‹åŠ¨è°ƒå‚
#      - è®­ç»ƒç¨³å®š,æ•ˆæœæœ€å¥½
#
#    pixel_fusion (åƒç´ çº§èåˆ):
#      - åœ¨RGBç©ºé—´èåˆå†ç¼–ç 
#      - æ˜¾å­˜å‹å¥½
#      - å¯èƒ½æŸå¤±éƒ¨åˆ†ç»†èŠ‚
#
# 2. use_residual_fusion:
#    true:  x_cond = vis + Î±*(sem - vis)  # ä¿ç•™å¯è§å…‰åŸºç¡€
#    false: x_cond = (1-Î±)*vis + Î±*sem    # æ ‡å‡†åŠ æƒ
#
# 3. æ˜¾å­˜å ç”¨ (batch_size=4):
#    - weighted/learnable: ~20GB
#    - pixel_fusion: ~18GB
#
# 4. æ¨èè®­ç»ƒæ­¥æ•°:
#    - å¿«é€ŸéªŒè¯: 500 steps
#    - å®Œæ•´è®­ç»ƒ: 5000-10000 steps
#
# ========================================
