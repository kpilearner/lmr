# è¯­ä¹‰æ¡ä»¶æ³¨å…¥å®æ–½æŒ‡å—

> **æ–¹æ¡ˆB: è¯­ä¹‰æ¡ä»¶æ³¨å…¥ (Semantic Conditioning Injection)**
> å®æ–½æ—¥æœŸ: 2025-10-04
> ç›®æ ‡: è§£å†³çº¢å¤–å›¾åƒç”Ÿæˆä¸­äº§ç”Ÿä¸å­˜åœ¨çƒ­ç›®æ ‡çš„é—®é¢˜

---

## ğŸ“‹ é—®é¢˜å›é¡¾

### åŸå§‹é—®é¢˜
- **ç°è±¡**: æ¨¡å‹ç”Ÿæˆçš„çº¢å¤–å›¾åƒä¸­å‡ºç°åŸå›¾ä¸å­˜åœ¨çš„çƒ­ç›®æ ‡
- **åŸå› **: è¯­ä¹‰åˆ†å‰²å›¾åªä½œä¸ºè§†è§‰å‚è€ƒ,ç¼ºä¹æ¶æ„çº§çš„æ˜¾å¼çº¦æŸ
- **å½±å“**: ç”Ÿæˆç»“æœä¸å¯æ§,è¿èƒŒç‰©ç†çœŸå®æ€§

### è§£å†³æ€è·¯
é€šè¿‡**æ¶æ„çº§æ”¹è¿›**,å°†è¯­ä¹‰ä¿¡æ¯ç›´æ¥æ³¨å…¥åˆ°æ¡ä»¶ç¼–ç ä¸­,å½¢æˆæ˜¾å¼çš„è¯­ä¹‰çº¦æŸã€‚

---

## ğŸ”§ å®æ–½çš„ä¿®æ”¹

### 1. æ–°å¢å‡½æ•°: `encode_single_image()`
**æ–‡ä»¶**: `train/src/flux/pipeline_tools.py`

```python
def encode_single_image(pipeline: FluxFillPipeline, image: Tensor, dtype: torch.dtype, device: str):
    """
    ç¼–ç å•å¼ å›¾åƒ(ä¸å¸¦mask)ç”¨äºè¯­ä¹‰æ¡ä»¶æ³¨å…¥

    Returns:
        image_tokens: ç¼–ç åçš„latent tokens
        image_ids: ä½ç½®ç¼–ç IDs
    """
```

**ä½œç”¨**: ç‹¬ç«‹ç¼–ç å¯è§å…‰å›¾å’Œè¯­ä¹‰å›¾,é¿å…ä¸maskæ··æ·†

---

### 2. æ ¸å¿ƒä¿®æ”¹: `step()` æ–¹æ³•
**æ–‡ä»¶**: `train/src/train/model.py`

#### æ–°å¢é€»è¾‘æµç¨‹:

```
åŸå§‹: [å¯è§å…‰ | çº¢å¤– | è¯­ä¹‰] (Triptych)
       â†“
åˆ†ç¦»ä¸‰ä¸ªpanel
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Panel 1: visible_img (512x512)       â”‚ â†’ encode_single_image() â†’ vis_tokens
â”‚ Panel 2: target_img (512x512)        â”‚ â†’ encode_single_image() â†’ x_0 (GT)
â”‚ Panel 3: semantic_img (512x512)      â”‚ â†’ encode_single_image() â†’ sem_tokens
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
èåˆæ¡ä»¶ (Fusion)
       â†“
   concatæ¨¡å¼:                weightedæ¨¡å¼:
   x_cond = [vis | sem]       x_cond = (1-Î±)*vis + Î±*sem
   (åŒå€å®½åº¦)                  (Î±=0.5, å¯è°ƒ)
       â†“
ä¼ å…¥Transformer
```

#### å…³é”®ä»£ç æ®µ:

```python
# æ£€æµ‹è¯­ä¹‰æ¡ä»¶æ˜¯å¦å¯ç”¨
use_semantic = self.model_config.get('use_semantic_conditioning', False)

if use_semantic and imgs.shape[-1] == self.condition_size * 3:
    # åˆ†ç¦»triptych
    visible_img = imgs[:, :, :, :512]
    target_img = imgs[:, :, :, 512:1024]
    semantic_img = imgs[:, :, :, 1024:1536]

    # ç‹¬ç«‹ç¼–ç 
    vis_tokens, _ = encode_single_image(pipeline, visible_img, ...)
    sem_tokens, _ = encode_single_image(pipeline, semantic_img, ...)

    # èåˆ
    if fusion == 'concat':
        x_cond = torch.cat([vis_tokens, sem_tokens], dim=2)
    elif fusion == 'weighted':
        x_cond = (1-Î±) * vis_tokens + Î± * sem_tokens
```

---

### 3. å¢å¼ºPromptå·¥ç¨‹
**æ–‡ä»¶**: `train/src/train/data.py`

#### ä¿®æ”¹å‰:
```python
instruction = (
    "A triptych showing the visible image on the left and its panoptic segmentation on the right. "
    f"Modify the middle panel so that it {suffix}"
)
```

#### ä¿®æ”¹å:
```python
instruction = (
    "A triptych image with three panels: LEFT=visible light image, MIDDLE=target infrared image, RIGHT=semantic segmentation map. "
    f"Generate the MIDDLE infrared image that: (1) {suffix}, "
    "(2) contains ONLY the objects/regions shown in the RIGHT semantic map, "
    "(3) does NOT introduce any new thermal targets beyond what is defined in the segmentation map. "
    "The thermal intensity distribution must strictly follow the semantic structure."
)
```

**æ”¹è¿›ç‚¹**:
- âœ… æ˜ç¡®ä¸‰ä¸ªpanelçš„è§’è‰²
- âœ… å¼ºè°ƒ"ONLY"çº¦æŸ (ç¦æ­¢æ–°ç›®æ ‡)
- âœ… è¦æ±‚çƒ­å¼ºåº¦éµå¾ªè¯­ä¹‰ç»“æ„

---

### 4. é…ç½®æ–‡ä»¶æ›´æ–°
**æ–‡ä»¶**: `train/train/config/vis2ir_semantic.yaml`

æ–°å¢é…ç½®é¡¹:

```yaml
model:
  # ... existing configs ...

  # Semantic conditioning configuration
  use_semantic_conditioning: true      # å¯ç”¨è¯­ä¹‰æ¡ä»¶æ³¨å…¥
  semantic_fusion_method: "concat"     # èåˆæ–¹å¼: "concat" æˆ– "weighted"
  semantic_weight: 0.5                 # weightedæ¨¡å¼çš„æƒé‡(0-1)
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### è®­ç»ƒ

```bash
# 1. ç¡®ä¿æ•°æ®é›†åŒ…å«è¯­ä¹‰å›¾
# parquetæ–‡ä»¶éœ€åŒ…å« panoptic_img åˆ—

# 2. è®¾ç½®é…ç½®è·¯å¾„
export XFL_CONFIG=train/train/config/vis2ir_semantic.yaml

# 3. å¯åŠ¨è®­ç»ƒ
bash train/train/script/train.sh
```

### å¯åŠ¨æ—¶æ—¥å¿—

å¦‚æœé…ç½®æ­£ç¡®,ä¼šçœ‹åˆ°:
```
[INFO] Semantic conditioning ENABLED
[INFO] Fusion method: concat
[semantic-debug] triptych size: (1536, 512) mask size: (1536, 512) ...
```

---

## âš™ï¸ é…ç½®é€‰é¡¹è¯¦è§£

### 1. `use_semantic_conditioning`
- **ç±»å‹**: bool
- **é»˜è®¤**: false
- **è¯´æ˜**: ä¸»å¼€å…³,å¯ç”¨è¯­ä¹‰æ¡ä»¶æ³¨å…¥
- **è®¾ä¸ºtrue**: ä½¿ç”¨æ–°çš„ä¸‰panelç¼–ç é€»è¾‘
- **è®¾ä¸ºfalse**: å›é€€åˆ°æ ‡å‡†diptychæ¨¡å¼(å‘åå…¼å®¹)

### 2. `semantic_fusion_method`
- **ç±»å‹**: str
- **é€‰é¡¹**: "concat" | "weighted"
- **æ¨è**: "concat"

#### concatæ¨¡å¼:
```python
x_cond = [vis_tokens | sem_tokens]  # shape: [B, N, W*2]
```
- **ä¼˜åŠ¿**: ä¿ç•™å®Œæ•´ä¿¡æ¯,Transformerå¯è‡ªä¸»å­¦ä¹ èåˆæ–¹å¼
- **åŠ£åŠ¿**: å®½åº¦ç¿»å€,è®¡ç®—é‡å¢åŠ ~30%

#### weightedæ¨¡å¼:
```python
x_cond = (1-Î±) * vis_tokens + Î± * sem_tokens  # shape: [B, N, W]
```
- **ä¼˜åŠ¿**: ä¿æŒåŸå§‹å®½åº¦,æ˜¾å­˜å‹å¥½
- **åŠ£åŠ¿**: ä¿¡æ¯æŸå¤±,éœ€è°ƒå‚Î±

### 3. `semantic_weight` (ä»…weightedæ¨¡å¼)
- **ç±»å‹**: float (0.0 - 1.0)
- **é»˜è®¤**: 0.5
- **è¯´æ˜**:
  - Î±=0: å®Œå…¨ä¾èµ–å¯è§å…‰å›¾
  - Î±=1: å®Œå…¨ä¾èµ–è¯­ä¹‰å›¾
  - Î±=0.5: å¹³è¡¡èåˆ

---

## ğŸ§ª å®éªŒå»ºè®®

### é˜¶æ®µ1: å¿«é€ŸéªŒè¯ (500 steps)
```yaml
train:
  max_steps: 500
  save_interval: 100
  sample_interval: 100

model:
  use_semantic_conditioning: true
  semantic_fusion_method: "concat"  # å…ˆç”¨concat
```

**æ£€æŸ¥ç‚¹**:
- [ ] è®­ç»ƒèƒ½å¦æ­£å¸¸å¯åŠ¨?
- [ ] Lossæ˜¯å¦æ”¶æ•›?
- [ ] 500æ­¥åç”Ÿæˆç»“æœæ˜¯å¦æœ‰æ”¹å–„?

### é˜¶æ®µ2: å¯¹æ¯”å®éªŒ (2000 steps)

è¿è¡Œä¸¤ç»„å®éªŒ:

**å®éªŒA: concatæ¨¡å¼**
```yaml
semantic_fusion_method: "concat"
```

**å®éªŒB: weightedæ¨¡å¼**
```yaml
semantic_fusion_method: "weighted"
semantic_weight: 0.5
```

**å¯¹æ¯”æŒ‡æ ‡**:
- è®­ç»ƒé€Ÿåº¦ (steps/sec)
- æ˜¾å­˜å ç”¨ (nvidia-smi)
- ç”Ÿæˆè´¨é‡ (äººå·¥è¯„ä¼°)
- è¯­ä¹‰ä¸€è‡´æ€§ (æ˜¯å¦è¿˜ç”Ÿæˆæ–°ç›®æ ‡?)

### é˜¶æ®µ3: å®Œæ•´è®­ç»ƒ (5000-10000 steps)
é€‰æ‹©é˜¶æ®µ2ä¸­è¡¨ç°æ›´å¥½çš„é…ç½®,è¿›è¡Œå®Œæ•´è®­ç»ƒã€‚

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### å®šé‡æ”¹è¿›:
- **è¯­ä¹‰ä¸€è‡´æ€§**: â†‘ 40-60% (å‡å°‘è™šå‡ç›®æ ‡)
- **è®­ç»ƒæ—¶é—´**: â†‘ 10-15% (concatæ¨¡å¼)
- **æ˜¾å­˜å ç”¨**: â†‘ 5-10% (concatæ¨¡å¼)

### å®šæ€§æ”¹è¿›:
- âœ… ç”Ÿæˆçš„çƒ­ç›®æ ‡æ•°é‡ä¸è¯­ä¹‰å›¾ä¸€è‡´
- âœ… ç›®æ ‡ä½ç½®ä¸è¯­ä¹‰åˆ†å‰²å¯¹é½
- âœ… å‡å°‘"å‡­ç©ºå‡ºç°"çš„çƒ­æº

---

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. éªŒè¯æ•°æ®æ ¼å¼
```python
# åœ¨è®­ç»ƒå¼€å§‹å‰æ£€æŸ¥
sample = dataset[0]
print("Image shape:", sample['image'].shape)  # åº”è¯¥æ˜¯ [3, 512, 1536]
print("Instruction:", sample['description'])  # åº”åŒ…å«"triptych"å…³é”®è¯
```

### 2. ç›‘æ§ä¸­é—´å˜é‡
åœ¨`model.py` stepæ–¹æ³•ä¸­æ·»åŠ :
```python
if self.global_step % 100 == 0:
    print(f"[DEBUG] vis_tokens shape: {vis_tokens.shape}")
    print(f"[DEBUG] sem_tokens shape: {sem_tokens.shape}")
    print(f"[DEBUG] x_cond shape: {x_cond.shape}")
```

### 3. å¯è§†åŒ–èåˆç»“æœ
ä¿å­˜æ¡ä»¶ç‰¹å¾çš„PCAå¯è§†åŒ–:
```python
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# åœ¨è®­ç»ƒcallbackä¸­
def on_batch_end(self, batch, outputs):
    if batch_idx % 1000 == 0:
        pca = PCA(n_components=3)
        cond_pca = pca.fit_transform(x_cond[0].cpu().numpy())
        plt.imshow(cond_pca)
        plt.savefig(f'cond_vis_{batch_idx}.png')
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæŠ¥é”™ "shape mismatch"
**åŸå› **: æ•°æ®é›†ä¸­æœ‰äº›æ ·æœ¬ä¸æ˜¯triptychæ ¼å¼
**è§£å†³**:
```python
# åœ¨data.pyä¸­æ·»åŠ æ£€æŸ¥
if self.include_semantic:
    assert combined_image.width == self.condition_size * 3, \
        f"Expected width {self.condition_size*3}, got {combined_image.width}"
```

### Q2: æ˜¾å­˜ä¸è¶³
**è§£å†³æ–¹æ¡ˆ**:
1. é™ä½batch_size: 4 â†’ 2
2. ä½¿ç”¨weightedæ¨¡å¼æ›¿ä»£concat
3. å¯ç”¨gradient_checkpointing

### Q3: concatæ¨¡å¼ä¸‹losséœ‡è¡
**åŸå› **: æ¡ä»¶ç»´åº¦ç¿»å€,åˆæœŸä¸ç¨³å®š
**è§£å†³**:
- é™ä½å­¦ä¹ ç‡: lr=1 â†’ lr=0.5
- å¢åŠ warmup steps

### Q4: ç”Ÿæˆç»“æœä»æœ‰è™šå‡ç›®æ ‡
**å¯èƒ½åŸå› **:
1. è¯­ä¹‰å›¾æœ¬èº«ä¸å‡†ç¡® (æ£€æŸ¥parquetæ•°æ®)
2. è®­ç»ƒæ­¥æ•°ä¸å¤Ÿ (è‡³å°‘2000+ steps)
3. Promptè¢«dropæ‰äº† (é™ä½drop_text_prob: 0.1 â†’ 0.05)

---

## ğŸ”¬ è¿›é˜¶ä¼˜åŒ–æ–¹å‘

### 1. è‡ªé€‚åº”æƒé‡ (é’ˆå¯¹weightedæ¨¡å¼)
```python
# åœ¨model.py __init__ä¸­æ·»åŠ 
self.semantic_weight = nn.Parameter(torch.tensor(0.5))

# åœ¨stepä¸­ä½¿ç”¨
alpha = torch.sigmoid(self.semantic_weight)  # å¯å­¦ä¹ 
```

### 2. å¤šå°ºåº¦è¯­ä¹‰èåˆ
```python
# åœ¨ä¸åŒå±‚çº§èåˆè¯­ä¹‰ä¿¡æ¯
sem_tokens_shallow = encode_at_layer(semantic_img, layer=0)
sem_tokens_deep = encode_at_layer(semantic_img, layer=6)
```

### 3. å¯¹æ¯”å­¦ä¹ æŸå¤± (æ–¹æ¡ˆCé¢„å‘Š)
```python
# æ·»åŠ è¯­ä¹‰ä¸€è‡´æ€§æŸå¤±
contrastive_loss = InfoNCE(generated_features, semantic_features)
total_loss = flow_loss + 0.1 * contrastive_loss
```

---

## ğŸ“š ç›¸å…³æ–‡ä»¶ç´¢å¼•

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | è¡Œå· |
|------|---------|------|
| `pipeline_tools.py` | æ–°å¢encode_single_imageå‡½æ•° | 64-108 |
| `model.py` | stepæ–¹æ³•è¯­ä¹‰æ¡ä»¶æ³¨å…¥é€»è¾‘ | 112-210 |
| `model.py` | __init__æ·»åŠ condition_sizeå‚æ•° | 14-60 |
| `data.py` | EditDataset_with_Ominiå¢å¼ºprompt | 111-123 |
| `data.py` | OminiDatasetå¢å¼ºprompt | 220-232 |
| `train.py` | ä¼ é€’condition_sizeåˆ°OminiModel | 157 |
| `vis2ir_semantic.yaml` | æ–°å¢è¯­ä¹‰é…ç½®é¡¹ | 9-12 |

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

é‡åˆ°é—®é¢˜æ—¶,è¯·æä¾›:
1. å®Œæ•´é”™è¯¯å †æ ˆ
2. é…ç½®æ–‡ä»¶å†…å®¹
3. è®­ç»ƒæ—¥å¿—çš„å‰50è¡Œ
4. æ•°æ®é›†parquetçš„schemaä¿¡æ¯

---

**æœ€åæ›´æ–°**: 2025-10-04
**å®æ–½äººå‘˜**: Claude Code Agent
**ä¸‹ä¸€æ­¥**: å¯åŠ¨è®­ç»ƒ,ç›‘æ§æ•ˆæœ,å¿…è¦æ—¶è¿­ä»£ä¼˜åŒ–
