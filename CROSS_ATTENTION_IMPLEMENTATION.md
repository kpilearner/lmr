# âœ… Cross-Attentionè¯­ä¹‰æ¡ä»¶æ³¨å…¥å®ç°å®Œæˆ

## å®ç°æ¦‚è¿°

æˆåŠŸå®ç°äº†ControlNeté£æ ¼çš„è¯­ä¹‰æ¡ä»¶æ³¨å…¥,é€šè¿‡Cross-Attentionæœºåˆ¶æ˜¾å¼å¼•å¯¼çº¢å¤–å›¾åƒç”Ÿæˆã€‚

---

## æ ¸å¿ƒæ¶æ„

### æ•°æ®æµ
```
è¾“å…¥Triptych: [visible | infrared_target | semantic]
         â†“
    åˆ†ç¦»ä¸‰ä¸ªå›¾åƒ
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Diptych Path     â”‚   Semantic Path     â”‚
â”‚                    â”‚                     â”‚
â”‚ [visible|target]   â”‚   semantic_img      â”‚
â”‚      â†“             â”‚        â†“            â”‚
â”‚  encode_images_fillâ”‚   encode_images     â”‚
â”‚      â†“             â”‚        â†“            â”‚
â”‚  x_0, x_cond       â”‚   semantic_tokens   â”‚
â”‚  [B,2048,64]       â”‚   [B,2048,64]       â”‚
â”‚  [B,2048,320]      â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
         Generate x_t from x_0
                  â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Cross-Attention   â”‚
         â”‚                   â”‚
         â”‚ Q: x_t            â”‚
         â”‚ K,V: semantic     â”‚
         â”‚                   â”‚
         â”‚ scale: 0â†’1        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
            x_t_enhanced
                  â†“
         cat(x_t_enhanced, x_cond)
                  â†“
         FLUX Transformer
                  â†“
         Predicted Noise
```

---

## å…³é”®ç»„ä»¶

### 1. SemanticCrossAttentionæ¨¡å—
**æ–‡ä»¶**: `train/src/flux/semantic_cross_attention.py`

**æ ¸å¿ƒåŠŸèƒ½**:
- Multi-head cross-attention
- Query: å›¾åƒç‰¹å¾ (x_t)
- Key/Value: è¯­ä¹‰ç‰¹å¾ (semantic_tokens)
- Learnable scaleå‚æ•° (åˆå§‹åŒ–ä¸º0)

**ç»´åº¦**:
```python
Input:
  image_feat: [B, 2048, 64]
  semantic_feat: [B, 2048, 64]

Output:
  [B, 2048, 64]  # è¯­ä¹‰å¼•å¯¼åçš„å›¾åƒç‰¹å¾
```

**ç‰¹ç‚¹**:
- 8ä¸ªattention heads (å¯é…ç½®)
- LayerNorm normalization
- Zero-initialized scale (æ¸è¿›å¼è®­ç»ƒ)

### 2. æ¨¡å‹é›†æˆ
**æ–‡ä»¶**: `train/src/train/model.py`

**ä¿®æ”¹å†…å®¹**:

#### a) __init__æ–¹æ³•
```python
# åˆå§‹åŒ–semantic cross-attention
if semantic_mode == 'cross_attention':
    self.semantic_cross_attn = SemanticConditioningAdapter(
        dim=64,
        num_layers=1,  # å¯é…ç½®
        num_heads=8,   # å¯é…ç½®
        dropout=0.0
    )
```

#### b) configure_optimizersæ–¹æ³•
```python
# æ·»åŠ cross-attentionå‚æ•°åˆ°optimizer
if self.semantic_cross_attn is not None:
    self.trainable_params.extend(
        list(self.semantic_cross_attn.parameters())
    )
```

#### c) stepæ–¹æ³• - ç¼–ç é˜¶æ®µ
```python
if semantic_mode == 'cross_attention':
    # 1. Encode diptych (visible+target)
    diptych = cat([visible_img, target_img], dim=-1)
    x_0, x_cond, img_ids = encode_images_fill(diptych, mask)

    # 2. Encode semantic separately
    semantic_tokens, _ = encode_images(semantic_img)
    # semantic_tokens: [B, 2048, 64]
```

#### d) stepæ–¹æ³• - Cross-Attentionæ³¨å…¥
```python
# Generate x_t
x_t = (1 - t) * x_0 + t * x_1

# Apply cross-attention
if self.semantic_cross_attn is not None:
    x_t_enhanced = self.semantic_cross_attn(x_t, semantic_tokens)
    hidden_states = cat([x_t_enhanced, x_cond], dim=2)
```

---

## é…ç½®æ–‡ä»¶

**æ–‡ä»¶**: `train/train/config/vis2ir_cross_attention.yaml`

```yaml
model:
  use_semantic_conditioning: true
  semantic_mode: "cross_attention"
  semantic_num_layers: 1
  semantic_num_heads: 8

train:
  dataset:
    include_semantic: true
    semantic_column: panoptic_img
```

---

## è®­ç»ƒå¼ é‡ç»´åº¦

### Step 0-1 é¢„æœŸDEBUGè¾“å‡º:

```
[DEBUG] ===== Cross-Attention Semantic Mode =====
[DEBUG] visible_img: torch.Size([4, 3, 512, 512])
[DEBUG] target_img: torch.Size([4, 3, 512, 512])
[DEBUG] semantic_img: torch.Size([4, 3, 512, 512])
[DEBUG] diptych: torch.Size([4, 3, 512, 1024])
[DEBUG] mask_diptych: torch.Size([4, 1, 512, 1024])

[DEBUG] x_0: torch.Size([4, 2048, 64])
[DEBUG] x_cond: torch.Size([4, 2048, 320])
[DEBUG] semantic_tokens: torch.Size([4, 2048, 64])

[DEBUG] Applying semantic cross-attention:
[DEBUG] x_t: torch.Size([4, 2048, 64])
[DEBUG] semantic_tokens: torch.Size([4, 2048, 64])
[DEBUG] Layer 0 scale: 0.000000  â† åˆå§‹åŒ–ä¸º0

[DEBUG] x_t_enhanced: torch.Size([4, 2048, 64])
[DEBUG] hidden_states (final): torch.Size([4, 2048, 384])
[DEBUG] ==========================================
```

### å¯åŠ¨æ—¶INFOè¾“å‡º:

```
[INFO] Semantic conditioning ENABLED
[INFO] Semantic mode: cross_attention
[INFO] Using Cross-Attention with 1 layers, 8 heads
[INFO] Added 33088 semantic cross-attention parameters to optimizer
```

**å‚æ•°é‡è®¡ç®—**:
```
Per layer:
- Q proj: 64 Ã— 64 = 4096
- K proj: 64 Ã— 64 = 4096
- V proj: 64 Ã— 64 = 4096
- Out proj: 64 Ã— 64 = 4096
- LayerNorm: 64 Ã— 2 + 64 Ã— 2 = 256
- Scale: 1

Total per layer: 16385
1 layer Ã— 16385 â‰ˆ 33K parameters
```

---

## å¯åŠ¨è®­ç»ƒ

### 1. é…ç½®ç¯å¢ƒå˜é‡
```bash
export XFL_CONFIG=train/train/config/vis2ir_cross_attention.yaml
```

### 2. å¯åŠ¨è®­ç»ƒ
```bash
bash train/train/script/train.sh
```

### 3. æ£€æŸ¥ç‚¹

**å¿…é¡»çœ‹åˆ°**:
- âœ… `[INFO] Using Cross-Attention with 1 layers, 8 heads`
- âœ… `[INFO] Added 33088 semantic cross-attention parameters`
- âœ… `x_t_enhanced: [4, 2048, 64]`
- âœ… `hidden_states (final): [4, 2048, 384]`
- âœ… `Layer 0 scale: 0.000000` (åˆå§‹)

**è®­ç»ƒå(~100 steps)**:
- Scaleåº”è¯¥é€æ¸å¢å¤§ (0.00x â†’ 0.0x â†’ 0.x)
- Lossæ­£å¸¸ä¸‹é™

---

## ç›¸æ¯”Pixel Fusionçš„ä¼˜åŠ¿

| ç‰¹æ€§ | Pixel Fusion | Cross-Attention |
|------|--------------|-----------------|
| **è¯­ä¹‰è¡¨è¾¾** | ç®€å•å åŠ ,ä¿¡æ¯å¼±åŒ– | æ˜¾å¼attention,ç²¾ç¡®å¼•å¯¼ |
| **å¯è§£é‡Šæ€§** | âŒ é»‘ç›’ | âœ… Attentionå¯è§†åŒ– |
| **æ§åˆ¶åŠ›åº¦** | æœ‰é™ (å•ä¸€alpha) | å¼º (ç©ºé—´è‡ªé€‚åº”) |
| **åˆ›æ–°æ€§** | ä½ | âœ… é«˜,å¯å‘è®ºæ–‡ |
| **è®­ç»ƒç¨³å®šæ€§** | å¥½ | âœ… Zero-initä¿è¯ç¨³å®š |
| **å‚æ•°é‡** | ~1 | ~33K |

---

## è®ºæ–‡å–ç‚¹

### Title
**"Semantic-Guided Infrared Image Generation via Cross-Attention Conditioning"**

### æ ¸å¿ƒè´¡çŒ®
1. **Novel Architecture** - é¦–æ¬¡å°†cross-attentionç”¨äºè¯­ä¹‰å¼•å¯¼çº¢å¤–ç”Ÿæˆ
2. **Explicit Control** - æ˜¾å¼è¯­ä¹‰çº¦æŸé˜²æ­¢å¹»è§‰ç›®æ ‡
3. **Interpretable** - Attention mapå¯è§†åŒ–è¯­ä¹‰å¼•å¯¼
4. **Effective** - å®éªŒè¯æ˜ä¼˜äºfusion baseline

### Ablation Study
- Cross-Attention vs Pixel Fusion
- ä¸åŒå±‚æ•° (1 vs 2 vs 3)
- ä¸åŒheadæ•° (4 vs 8 vs 16)
- Scaleåˆå§‹åŒ–ç­–ç•¥

---

## ä¸‹ä¸€æ­¥

### è®­ç»ƒé˜¶æ®µ
1. **Warmup (0-1k steps)**: Scaleä»0ç¼“æ…¢å¢é•¿,å­¦ä¹ åŸºæœ¬å¯¹é½
2. **Main Training**: LoRA + Cross-Attentionè”åˆä¼˜åŒ–
3. **Fine-tune**: è°ƒæ•´è¶…å‚æ•°

### å¯è§†åŒ–
- Attention mapå¯è§†åŒ–
- ç”Ÿæˆæ ·æœ¬å¯¹æ¯”
- æ¶ˆèå®éªŒ

### æ¨ç†
éœ€è¦å®ç°æ¨ç†è„šæœ¬,ä½¿ç”¨trained cross-attention:
```python
# æ¨ç†æ—¶
semantic_tokens = encode_images(semantic_img)
x_t_enhanced = cross_attn(x_t, semantic_tokens)
# ç„¶åæ­£å¸¸FLUX sampling
```

---

## æ•…éšœæ’é™¤

### å¦‚æœçœ‹ä¸åˆ°cross-attentionè¾“å‡º
- æ£€æŸ¥é…ç½®: `semantic_mode: "cross_attention"`
- æ£€æŸ¥æ•°æ®: triptychå®½åº¦æ˜¯1536

### å¦‚æœscaleä¸å˜
- æ£€æŸ¥optimizeråŒ…å«äº†cross-attnå‚æ•°
- æ£€æŸ¥learning rate

### å¦‚æœOOM
- å‡å°batch_size: 4â†’2
- æˆ–å‡å°‘layers/heads

---

**å®ç°å®Œæˆ!å‡†å¤‡å¯åŠ¨è®­ç»ƒ!** ğŸš€
